{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload a dataset \n",
    "\n",
    "file_path = os.path.join(sys.path[0], \"dialogues_v3_Evgeny.xlsx\")\n",
    "df = pd.read_excel(file_path, header = 1, \n",
    "                   names = ['id', 'pagetitle', 'orig_user', 'reply_user', 'orig', 'reply',\n",
    "       'disagreement', 'orig_id', 'reply_id', 'orig_toxicity',\n",
    "       'orig_severe_toxicity', 'reply_toxicity', 'reply_severe_toxicity',\n",
    "       'conv_id', 'COP', 'COP_flag', 'COP_why', 'FCG', 'FCG_flag',\n",
    "       'FCG_why', 'RT', 'RT_flag', 'RT_why', 'PS',\n",
    "       'PS_flag', 'PS_why', 'Overall comment', 'escalated'], index_col = 'id', convert_float = True)\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# choose appropriate columns. drop lines without disagreement.\n",
    "df_ess = df[['orig', 'reply', 'COP', 'FCG', 'RT', 'PS']].dropna()\n",
    "labels = ['COP', 'FCG', 'RT', 'PS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Split sets by train+dev and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Test and train data split\n",
    "df_train, df_test = train_test_split(df_ess, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by train and test datasets\n",
    "X_train = list(df_train['reply'])\n",
    "X_test = list(df_test['reply'])\n",
    "y_all_train = df_train[labels]\n",
    "y_all_test = df_test[labels]\n",
    "# example label\n",
    "label = 'PS'\n",
    "y_train = y_all_train[label].tolist()\n",
    "y_test = y_all_test[label].tolist()\n",
    "# Divide train by train and dev\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    y_test\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    y_val\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFRobertaForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir='./results',         # output directory\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=2,\n",
    "    eval_steps = 50,                # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "with training_args.strategy.scope():\n",
    "    model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fea75e85980>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fea75e85980>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-74ab856290cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_training_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = TFTrainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TFTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "output=trainer.predict(test_dataset)[0]\n",
    "\n",
    "def get_prediction_labels(output):\n",
    "    pred_labels = []\n",
    "    for pair in output:\n",
    "        if pair[0] > pair[1]:\n",
    "            pred_labels.append(0)\n",
    "        else:\n",
    "            pred_labels.append(1)\n",
    "    return pred_labels\n",
    "\n",
    "pred = get_prediction_labels(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,   0],\n",
       "       [ 75,   0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "cm=confusion_matrix(y_test,pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f86fe2b7650>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd = ConfusionMatrixDisplay(cm, display_labels = [0,1])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
