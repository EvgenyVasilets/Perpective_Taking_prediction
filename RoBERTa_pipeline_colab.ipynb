{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Internship - RoBERTa pipeline.ipynb",
      "provenance": [],
      "mount_file_id": "1utLiXXH8cpdMEiCFL3hveuKrQtpr8hzI",
      "authorship_tag": "ABX9TyM2EOKkD3IcoDAiXE3DsO0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvgenyVasilets/Perpective_Taking_prediction/blob/main/RoBERTa_pipeline_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiQz2Gw2nvsZ"
      },
      "source": [
        "from google.colab import output\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK20QDpMMYdk",
        "outputId": "a1d15620-18ef-4a90-a810-8e9a9fa68667"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Qz_sQSMb9z"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GShetP-XMpYq"
      },
      "source": [
        "# upload a dataset \n",
        "\n",
        "file_path_Evgeny = \"/content/drive/MyDrive/Colab Notebooks/dialogues_v3_Evgeny.xlsx\"\n",
        "file_path_Tijs = \"/content/drive/MyDrive/Colab Notebooks/dialogues_v3_Tijs.xlsx\"\n",
        "col_names = ['id', 'pagetitle', 'orig_user', 'reply_user', 'orig', 'reply',\n",
        "       'disagreement', 'orig_id', 'reply_id', 'orig_toxicity',\n",
        "       'orig_severe_toxicity', 'reply_toxicity', 'reply_severe_toxicity',\n",
        "       'conv_id', 'COP', 'COP_flag', 'COP_why', 'FCG', 'FCG_flag',\n",
        "       'FCG_why', 'RT', 'RT_flag', 'RT_why', 'PS',\n",
        "       'PS_flag', 'PS_why', 'Overall comment', 'escalated']\n",
        "csv_parameters = {\n",
        "        'header' : 1, \n",
        "        'names' : col_names, \n",
        "        'index_col' :'id', \n",
        "        'convert_float' : True}\n",
        "\n",
        "df_Evgeny = pd.read_excel(file_path_Evgeny, **csv_parameters)\n",
        "df_Tijs = pd.read_excel(file_path_Tijs, **csv_parameters)\n",
        "\n",
        "df = pd.concat([df_Evgeny, df_Tijs])\n",
        "\n",
        "df = df.convert_dtypes()\n",
        "\n",
        "# choose appropriate columns. drop lines without disagreement.\n",
        "df_ess = df[['orig', 'reply', 'COP', 'FCG', 'RT', 'PS']].dropna()\n",
        "labels = ['COP', 'FCG', 'RT', 'PS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXKTh2-kNnZ-"
      },
      "source": [
        "\n",
        "\n",
        "# Split dataset by train+val and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDcuVwEyvZIe"
      },
      "source": [
        "randoms_states = [10, 100, 1000]\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import RobertaTokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxhtCDtONMU8",
        "outputId": "011830a3-f2ae-4d81-d2dc-44e44334b840"
      },
      "source": [
        "\n",
        "# Test and train data split\n",
        "df_train, df_test = train_test_split(df_ess, random_state = 42, test_size = .2)\n",
        "# Divide by train and test datasets\n",
        "X_train = list(df_train['reply'])\n",
        "X_test = list(df_test['reply'])\n",
        "y_all_train = df_train[labels]\n",
        "y_all_test = df_test[labels]\n",
        "# example label\n",
        "label = 'RT'\n",
        "y_train = y_all_train[label].tolist()\n",
        "y_test = y_all_test[label].tolist()\n",
        "# Divide train by train and dev\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # 0.2 x 0.8 = 0.16\n",
        "\n",
        "print('X_train length:', len(X_train))\n",
        "print('X_val length:', len(X_val))\n",
        "print('X_test length:', len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train length: 1072\n",
            "X_val length: 268\n",
            "X_test length: 335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExMy0EBSPB96"
      },
      "source": [
        "os.path.isdir('new_folder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSacM-8wPDEz"
      },
      "source": [
        "# RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFc4ngLXPO-r",
        "outputId": "0c4f4d76-6c4f-4e4e-d754-1067dd1b71ae"
      },
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8fkO0KQPQOn"
      },
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dXHvZ6NTHBg"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    y_val\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVlMYEN0Paay",
        "outputId": "e6c7abd7-4ce2-406b-d177-496d982abd16"
      },
      "source": [
        "from transformers import TFRobertaForSequenceClassification, TFTrainer, TFTrainingArguments, logging\n",
        "\n",
        "logging.set_verbosity_info()\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',         # output directory\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps = 50,\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.1,               # strength of weight decay\n",
        "    logging_steps=10,\n",
        "    logging_dir='./logs',\n",
        "    log_level = 'info',\n",
        "    logging_first_step = True,\n",
        "    disable_tqdm = False\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjcM2dgePl-C"
      },
      "source": [
        "from datasets import load_metric\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# metric = load_metric(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7KtdiuWPcSu",
        "outputId": "78384e71-d9c5-45d7-87cc-b7a99e2fe4ee"
      },
      "source": [
        "with training_args.strategy.scope():\n",
        "    model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/roberta-base/resolve/main/tf_model.h5 from cache at /root/.cache/huggingface/transformers/22fef2e3c5012c1a8f8d7f024e30275dd2925b076abb5131dc3d1068345b6426.d409db346b0c1408865b9785d36744ccb988186626309ae8f995f86511811602.h5\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJh9gvdzPeeo",
        "outputId": "04b03990-3af0-49f6-a9ab-1eb864231e60"
      },
      "source": [
        "trainer = TFTrainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,           # evaluation dataset\n",
        "    compute_metrics = compute_metrics)\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb && wandb login` see https://docs.wandb.com/huggingface.\n",
            "To use comet_ml logging, run `pip/conda install comet_ml` see https://www.comet.ml/docs/python-sdk/huggingface/\n",
            "***** Running training *****\n",
            "  Num examples = 1072\n",
            "  Num Epochs = 5.0\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Steps per epoch = 134\n",
            "  Total optimization steps = 670\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'loss': 0.6678722, 'learning_rate': 1e-07, 'epoch': 0.007462686567164179, 'step': 1}\n",
            "{'loss': 0.6525522, 'learning_rate': 1e-06, 'epoch': 0.07462686567164178, 'step': 10}\n",
            "{'loss': 0.63964754, 'learning_rate': 2e-06, 'epoch': 0.14925373134328357, 'step': 20}\n",
            "{'loss': 0.6302148, 'learning_rate': 2.9999999e-06, 'epoch': 0.22388059701492538, 'step': 30}\n",
            "{'loss': 0.6162568, 'learning_rate': 4e-06, 'epoch': 0.29850746268656714, 'step': 40}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "{'eval_loss': 0.5460033416748047, 'eval_f1': 0.44715447154471544, 'eval_precision': 0.40441176470588236, 'eval_recall': 0.5, 'epoch': 0.373134328358209, 'step': 50}\n",
            "{'loss': 0.6146742, 'learning_rate': 5.0000003e-06, 'epoch': 0.373134328358209, 'step': 50}\n",
            "{'loss': 0.60791653, 'learning_rate': 5.9999998e-06, 'epoch': 0.44776119402985076, 'step': 60}\n",
            "{'loss': 0.5886943, 'learning_rate': 6.9999996e-06, 'epoch': 0.5223880597014925, 'step': 70}\n",
            "{'loss': 0.5840543, 'learning_rate': 8e-06, 'epoch': 0.5970149253731343, 'step': 80}\n",
            "{'loss': 0.56585354, 'learning_rate': 9e-06, 'epoch': 0.6716417910447762, 'step': 90}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.4887691946590648, 'eval_f1': 0.44715447154471544, 'eval_precision': 0.40441176470588236, 'eval_recall': 0.5, 'epoch': 0.746268656716418, 'step': 100}\n",
            "{'loss': 0.5745842, 'learning_rate': 1.0000001e-05, 'epoch': 0.746268656716418, 'step': 100}\n",
            "{'loss': 0.5660775, 'learning_rate': 1.1e-05, 'epoch': 0.8208955223880597, 'step': 110}\n",
            "{'loss': 0.56273514, 'learning_rate': 1.19999995e-05, 'epoch': 0.8955223880597015, 'step': 120}\n",
            "{'loss': 0.56060356, 'learning_rate': 1.2999999e-05, 'epoch': 0.9701492537313433, 'step': 130}\n",
            "{'loss': 0.4524797, 'learning_rate': 1.3999999e-05, 'epoch': 1.044776119402985, 'step': 140}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.47469010072595935, 'eval_f1': 0.44715447154471544, 'eval_precision': 0.40441176470588236, 'eval_recall': 0.5, 'epoch': 1.1194029850746268, 'step': 150}\n",
            "{'loss': 0.52321017, 'learning_rate': 1.5000001e-05, 'epoch': 1.1194029850746268, 'step': 150}\n",
            "{'loss': 0.5121356, 'learning_rate': 1.6e-05, 'epoch': 1.1940298507462686, 'step': 160}\n",
            "{'loss': 0.51438904, 'learning_rate': 1.7e-05, 'epoch': 1.2686567164179103, 'step': 170}\n",
            "{'loss': 0.5114662, 'learning_rate': 1.8e-05, 'epoch': 1.3432835820895521, 'step': 180}\n",
            "{'loss': 0.49320957, 'learning_rate': 1.9e-05, 'epoch': 1.417910447761194, 'step': 190}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.565285794875201, 'eval_f1': 0.44602851323828924, 'eval_precision': 0.4040590405904059, 'eval_recall': 0.49772727272727274, 'epoch': 1.4925373134328357, 'step': 200}\n",
            "{'loss': 0.52231294, 'learning_rate': 2e-05, 'epoch': 1.4925373134328357, 'step': 200}\n",
            "{'loss': 0.52492, 'learning_rate': 2.0999998e-05, 'epoch': 1.5671641791044775, 'step': 210}\n",
            "{'loss': 0.5175222, 'learning_rate': 2.2e-05, 'epoch': 1.6417910447761193, 'step': 220}\n",
            "{'loss': 0.51173633, 'learning_rate': 2.3e-05, 'epoch': 1.716417910447761, 'step': 230}\n",
            "{'loss': 0.5036537, 'learning_rate': 2.3999999e-05, 'epoch': 1.7910447761194028, 'step': 240}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.42760338502771716, 'eval_f1': 0.7000603374737324, 'eval_precision': 0.6917721015357683, 'eval_recall': 0.7106643356643356, 'epoch': 1.8656716417910446, 'step': 250}\n",
            "{'loss': 0.49223372, 'learning_rate': 2.5e-05, 'epoch': 1.8656716417910446, 'step': 250}\n",
            "{'loss': 0.48445395, 'learning_rate': 2.5999998e-05, 'epoch': 1.9402985074626866, 'step': 260}\n",
            "{'loss': 0.4440254, 'learning_rate': 2.7e-05, 'epoch': 2.014925373134328, 'step': 270}\n",
            "{'loss': 0.38380286, 'learning_rate': 2.7999999e-05, 'epoch': 2.08955223880597, 'step': 280}\n",
            "{'loss': 0.40028685, 'learning_rate': 2.8999999e-05, 'epoch': 2.1641791044776117, 'step': 290}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.43203264124253216, 'eval_f1': 0.5175251880232723, 'eval_precision': 0.7431077694235588, 'eval_recall': 0.5339160839160839, 'epoch': 2.2388059701492535, 'step': 300}\n",
            "{'loss': 0.41135335, 'learning_rate': 3.0000001e-05, 'epoch': 2.2388059701492535, 'step': 300}\n",
            "{'loss': 0.42338994, 'learning_rate': 3.1e-05, 'epoch': 2.3134328358208958, 'step': 310}\n",
            "{'loss': 0.4245249, 'learning_rate': 3.2e-05, 'epoch': 2.388059701492537, 'step': 320}\n",
            "{'loss': 0.42558277, 'learning_rate': 3.3e-05, 'epoch': 2.4626865671641793, 'step': 330}\n",
            "{'loss': 0.43141845, 'learning_rate': 3.4e-05, 'epoch': 2.5373134328358207, 'step': 340}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.395480660831227, 'eval_f1': 0.7185566783347643, 'eval_precision': 0.7202111613876321, 'eval_recall': 0.7169580419580419, 'epoch': 2.611940298507463, 'step': 350}\n",
            "{'loss': 0.41824597, 'learning_rate': 3.4999997e-05, 'epoch': 2.611940298507463, 'step': 350}\n",
            "{'loss': 0.42880872, 'learning_rate': 3.6e-05, 'epoch': 2.6865671641791042, 'step': 360}\n",
            "{'loss': 0.43268734, 'learning_rate': 3.6999998e-05, 'epoch': 2.7611940298507465, 'step': 370}\n",
            "{'loss': 0.42895064, 'learning_rate': 3.8e-05, 'epoch': 2.835820895522388, 'step': 380}\n",
            "{'loss': 0.42417878, 'learning_rate': 3.8999995e-05, 'epoch': 2.91044776119403, 'step': 390}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.5950232113108915, 'eval_f1': 0.4625292740046838, 'eval_precision': 0.5298507462686567, 'eval_recall': 0.5027972027972027, 'epoch': 2.9850746268656714, 'step': 400}\n",
            "{'loss': 0.42588693, 'learning_rate': 4e-05, 'epoch': 2.9850746268656714, 'step': 400}\n",
            "{'loss': 0.6386276, 'learning_rate': 4.1e-05, 'epoch': 3.0597014925373136, 'step': 410}\n",
            "{'loss': 0.47918198, 'learning_rate': 4.1999996e-05, 'epoch': 3.1343283582089554, 'step': 420}\n",
            "{'loss': 0.4127087, 'learning_rate': 4.2999996e-05, 'epoch': 3.208955223880597, 'step': 430}\n",
            "{'loss': 0.36985984, 'learning_rate': 4.4e-05, 'epoch': 3.283582089552239, 'step': 440}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.46522199406343345, 'eval_f1': 0.7041572671608121, 'eval_precision': 0.6917067307692308, 'eval_recall': 0.7230769230769231, 'epoch': 3.3582089552238807, 'step': 450}\n",
            "{'loss': 0.33857536, 'learning_rate': 4.4999997e-05, 'epoch': 3.3582089552238807, 'step': 450}\n",
            "{'loss': 0.34711486, 'learning_rate': 4.6e-05, 'epoch': 3.4328358208955225, 'step': 460}\n",
            "{'loss': 0.3418735, 'learning_rate': 4.6999998e-05, 'epoch': 3.5074626865671643, 'step': 470}\n",
            "{'loss': 0.33814257, 'learning_rate': 4.7999998e-05, 'epoch': 3.582089552238806, 'step': 480}\n",
            "{'loss': 0.32743064, 'learning_rate': 4.9e-05, 'epoch': 3.656716417910448, 'step': 490}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.4622124503640568, 'eval_f1': 0.6583877995642701, 'eval_precision': 0.701597565614302, 'eval_recall': 0.638986013986014, 'epoch': 3.7313432835820897, 'step': 500}\n",
            "{'loss': 0.3323088, 'learning_rate': 5e-05, 'epoch': 3.7313432835820897, 'step': 500}\n",
            "Saving checkpoint for step 500 at ./results/checkpoint/ckpt-1\n",
            "{'loss': 0.33073348, 'learning_rate': 4.7058824e-05, 'epoch': 3.8059701492537314, 'step': 510}\n",
            "{'loss': 0.32083473, 'learning_rate': 4.4117645e-05, 'epoch': 3.8805970149253732, 'step': 520}\n",
            "{'loss': 0.32178655, 'learning_rate': 4.117647e-05, 'epoch': 3.955223880597015, 'step': 530}\n",
            "{'loss': 0.31834877, 'learning_rate': 3.8235292e-05, 'epoch': 4.029850746268656, 'step': 540}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.4450379539938534, 'eval_f1': 0.6895810955961332, 'eval_precision': 0.6809302325581396, 'eval_recall': 0.772027972027972, 'epoch': 4.104477611940299, 'step': 550}\n",
            "{'loss': 0.26521927, 'learning_rate': 3.5294113e-05, 'epoch': 4.104477611940299, 'step': 550}\n",
            "{'loss': 0.2535642, 'learning_rate': 3.2352942e-05, 'epoch': 4.17910447761194, 'step': 560}\n",
            "{'loss': 0.24483737, 'learning_rate': 2.9411762e-05, 'epoch': 4.253731343283582, 'step': 570}\n",
            "{'loss': 0.23728919, 'learning_rate': 2.6470589e-05, 'epoch': 4.3283582089552235, 'step': 580}\n",
            "{'loss': 0.2625815, 'learning_rate': 2.352941e-05, 'epoch': 4.402985074626866, 'step': 590}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.5408688152537626, 'eval_f1': 0.6932001289075088, 'eval_precision': 0.6814903846153846, 'eval_recall': 0.7111888111888112, 'epoch': 4.477611940298507, 'step': 600}\n",
            "{'loss': 0.2513496, 'learning_rate': 2.0588232e-05, 'epoch': 4.477611940298507, 'step': 600}\n",
            "{'loss': 0.25160137, 'learning_rate': 1.7647057e-05, 'epoch': 4.552238805970149, 'step': 610}\n",
            "{'loss': 0.2639036, 'learning_rate': 1.4705881e-05, 'epoch': 4.6268656716417915, 'step': 620}\n",
            "{'loss': 0.26358795, 'learning_rate': 1.1764706e-05, 'epoch': 4.701492537313433, 'step': 630}\n",
            "{'loss': 0.26193044, 'learning_rate': 8.823528e-06, 'epoch': 4.776119402985074, 'step': 640}\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 268\n",
            "  Num examples in used in evaluation = 272\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.43445413252886605, 'eval_f1': 0.7246079762933695, 'eval_precision': 0.764749856239218, 'eval_recall': 0.7012237762237763, 'epoch': 4.850746268656716, 'step': 650}\n",
            "{'loss': 0.25475395, 'learning_rate': 5.8823525e-06, 'epoch': 4.850746268656716, 'step': 650}\n",
            "{'loss': 0.24920793, 'learning_rate': 2.9411763e-06, 'epoch': 4.925373134328359, 'step': 660}\n",
            "{'loss': 0.24423446, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 670}\n",
            "Training took: 0:14:32.828528\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjMbCYDGnU1M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKe91iG7nV5b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRuV6AcRVBKt",
        "outputId": "f3265aab-e536-471c-f09f-f7971d38a5cb"
      },
      "source": [
        "tester = TFTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "evaluation = tester.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb && wandb login` see https://docs.wandb.com/huggingface.\n",
            "To use comet_ml logging, run `pip/conda install comet_ml` see https://www.comet.ml/docs/python-sdk/huggingface/\n",
            "***** Running Evaluation *****\n",
            "  Num examples in dataset = 335\n",
            "  Num examples in used in evaluation = 336\n",
            "  Batch size = 16\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2739540281749907, 'eval_f1': 0.6576770945702984, 'eval_precision': 0.8366277685163135, 'eval_recall': 0.6168664737494833, 'epoch': 0, 'step': 0}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycH5bMZAg0Jk",
        "outputId": "bb4e623f-52c3-425d-ca8a-9552e42f6dd2"
      },
      "source": [
        "evaluation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_f1': 0.6576770945702984,\n",
              " 'eval_loss': 0.2739540281749907,\n",
              " 'eval_precision': 0.8366277685163135,\n",
              " 'eval_recall': 0.6168664737494833}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xbWPORCVSI_",
        "outputId": "608fb8ab-6e65-4e8a-c238-4e8521770489"
      },
      "source": [
        "output = tester.predict(test_dataset)\n",
        "logits, labels = output[0], output[1]\n",
        "\n",
        "pred = np.argmax(logits, axis=-1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples in dataset = 335\n",
            "  Batch size = 16\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lvxpfkhbGD5",
        "outputId": "144c34a2-53f8-4fea-eb87-b577fb9a8c40"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
        "cm=confusion_matrix(y_test, pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10,  31],\n",
              "       [  3, 291]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "p4eeX7ACbIS0",
        "outputId": "e34c46ad-d4f8-4984-d9f6-5abb03f327e0"
      },
      "source": [
        "cmd = ConfusionMatrixDisplay(cm, display_labels = [0,1])\n",
        "cmd.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f0226528b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVxuyVe2b7l7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}